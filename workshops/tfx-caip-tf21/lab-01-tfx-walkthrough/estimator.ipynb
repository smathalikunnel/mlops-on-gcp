{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " ?tf.feature_column.categorical_column_with_vocabulary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('outdir',ignore_errors=True)#start fresh every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    tf.feature_column.numeric_column(\"sq_footage\"),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('type',['apt','house'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'outdir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearRegressor(feat_cols,'outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    \n",
    "    features = {\n",
    "        'sq_footage':[1000,2000,3000,2000,1000,3000],\n",
    "        'type':['house','house','house','apt','apt','apt']\n",
    "    }\n",
    "    \n",
    "    labels = [500,1000,3000,2000,3000,1000]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 4041666.8, step = 0\n",
      "INFO:tensorflow:global_step/sec: 815.288\n",
      "INFO:tensorflow:loss = 1288194.9, step = 100 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1248.79\n",
      "INFO:tensorflow:loss = 1287096.6, step = 200 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1361.81\n",
      "INFO:tensorflow:loss = 1286166.9, step = 300 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1321.84\n",
      "INFO:tensorflow:loss = 1285344.9, step = 400 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1299.78\n",
      "INFO:tensorflow:loss = 1284599.6, step = 500 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1321.24\n",
      "INFO:tensorflow:loss = 1283913.4, step = 600 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1306.16\n",
      "INFO:tensorflow:loss = 1283273.9, step = 700 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1359.29\n",
      "INFO:tensorflow:loss = 1282672.4, step = 800 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1336.33\n",
      "INFO:tensorflow:loss = 1282103.4, step = 900 (0.073 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Loss for final step: 1281567.2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7f28384dd710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_input_fn,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_fn():\n",
    "    \n",
    "    features = {\n",
    "        'sq_footage':[1000,2000,3000,2000,1000,3000],\n",
    "        'type':['house','house','house','apt','apt','apt']\n",
    "    }\n",
    "    \n",
    "    #labels = [500,1000,3000,2000,3000,1000]\n",
    "    return features#, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### following code disables eager mode. why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(predictions)\n",
    "\n",
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### following line gives unlimited predictions. why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in predictions:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change model easily, without changing input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'outdir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.estimator.DNNRegressor([30,15],feat_cols,'outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Items of feature_columns must be a <class 'tensorflow.python.feature_column.feature_column_v2.DenseColumn'>. You can wrap a categorical column with an embedding_column or indicator_column. Given: VocabularyListCategoricalColumn(key='type', vocabulary_list=('apt', 'house'), dtype=tf.string, default_value=-1, num_oov_buckets=0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a303e2d1f79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1180\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[0;32m-> 1211\u001b[0;31m                                            self.config)\n\u001b[0m\u001b[1;32m   1212\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1168\u001b[0m           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m           batch_norm=batch_norm)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     super(DNNRegressorV2, self).__init__(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_model_fn_v2\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    562\u001b[0m       \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m       mode=mode)\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m   \u001b[0;31m# In TRAIN mode, create optimizer and assign global_step variable to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn_builder_v2\u001b[0;34m(units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, features, mode)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m       \u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m       name='dnn')\n\u001b[0m\u001b[1;32m    500\u001b[0m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, name, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfeature_column_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feature_column_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         self._input_layer = dense_features_v2.DenseFeatures(\n\u001b[0;32m--> 293\u001b[0;31m             feature_columns=feature_columns, name=layer_name)\n\u001b[0m\u001b[1;32m    294\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/dense_features_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_StateManagerImplV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/dense_features.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexpected_column_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseColumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, expected_column_type, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;34m'You can wrap a categorical column with an '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             'embedding_column or indicator_column. Given: {}'.format(\n\u001b[0;32m--> 404\u001b[0;31m                 expected_column_type, column))\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Items of feature_columns must be a <class 'tensorflow.python.feature_column.feature_column_v2.DenseColumn'>. You can wrap a categorical column with an embedding_column or indicator_column. Given: VocabularyListCategoricalColumn(key='type', vocabulary_list=('apt', 'house'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
     ]
    }
   ],
   "source": [
    "model2.train(train_input_fn,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols2 = [\n",
    "    tf.feature_column.numeric_column(\"sq_footage\"),\n",
    "    tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('type',['apt','house']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'outdir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.estimator.DNNRegressor([30,15],feat_cols2,'outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2626696.2, step = 0\n",
      "INFO:tensorflow:global_step/sec: 826.782\n",
      "INFO:tensorflow:loss = 2107401.5, step = 100 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1165.07\n",
      "INFO:tensorflow:loss = 1902288.1, step = 200 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1169.51\n",
      "INFO:tensorflow:loss = 1761490.1, step = 300 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1213.29\n",
      "INFO:tensorflow:loss = 1656244.0, step = 400 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1208.86\n",
      "INFO:tensorflow:loss = 1574932.0, step = 500 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1201.7\n",
      "INFO:tensorflow:loss = 1511249.5, step = 600 (0.081 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 602 vs previous value: 602. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 1200.03\n",
      "INFO:tensorflow:loss = 1461149.4, step = 700 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1194.96\n",
      "INFO:tensorflow:loss = 1421750.4, step = 800 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1178.44\n",
      "INFO:tensorflow:loss = 1390866.8, step = 900 (0.087 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Loss for final step: 1367135.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x7f27b039a450>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train(train_input_fn,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model2.predict(predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do not execute - turns off eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(pred))\n",
    "# print(next(pred))\n",
    "# print(next(pred))\n",
    "# print(next(pred))\n",
    "# print(next(pred))\n",
    "# print(next(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                        model.ckpt-0.meta\r\n",
      "graph.pbtxt                       model.ckpt-1000.data-00000-of-00001\r\n",
      "model.ckpt-0.data-00000-of-00001  model.ckpt-1000.index\r\n",
      "model.ckpt-0.index                model.ckpt-1000.meta\r\n"
     ]
    }
   ],
   "source": [
    "%ls outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'sq_footage': [1000,2000,3000,2000,1000,3000],\n",
    "    'type':['house','house','house','apt','apt','apt'],\n",
    "    'price':[500,1000,3000,2000,3000,1000]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function tensorflow_estimator.python.estimator.inputs.pandas_io.pandas_input_fn(x, y=None, batch_size=128, num_epochs=1, shuffle=None, queue_capacity=1000, num_threads=1, target_column='target')>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.estimator.inputs.pandas_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_input_fn(df):\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        df,\n",
    "        df['price'],\n",
    "        batch_size=128,\n",
    "        num_epochs=10,\n",
    "        shuffle=True,\n",
    "        queue_capacity=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 4877910.5, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1...\n",
      "INFO:tensorflow:Saving checkpoints for 1 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1...\n",
      "INFO:tensorflow:Loss for final step: 4877910.5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x7f27b039a450>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train(pandas_input_fn(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                        model.ckpt-0.meta\r\n",
      "graph.pbtxt                       model.ckpt-1.data-00000-of-00001\r\n",
      "model.ckpt-0.data-00000-of-00001  model.ckpt-1.index\r\n",
      "model.ckpt-0.index                model.ckpt-1.meta\r\n"
     ]
    }
   ],
   "source": [
    "%ls outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model2.predict(predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(pred))\n",
    "# print(next(pred))\n",
    "# print(next(pred))\n",
    "# print(next(pred))\n",
    "# print(next(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sq_footage</th>\n",
       "      <th>type</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>house</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>house</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>house</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>apt</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>apt</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3000</td>\n",
       "      <td>apt</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sq_footage   type  price\n",
       "0        1000  house    500\n",
       "1        2000  house   1000\n",
       "2        3000  house   3000\n",
       "3        2000    apt   2000\n",
       "4        1000    apt   3000\n",
       "5        3000    apt   1000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_eval_fn(df):\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        df,\n",
    "        df['price'],\n",
    "        batch_size=128,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-13T05:57:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.26103s\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-13-05:57:16\n",
      "INFO:tensorflow:Saving dict for global step 1: average_loss = 4806885.0, global_step = 1, label/mean = 1750.0, loss = 4806885.0, prediction/mean = -200.46771\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: outdir/model.ckpt-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 4806885.0,\n",
       " 'label/mean': 1750.0,\n",
       " 'loss': 4806885.0,\n",
       " 'prediction/mean': -200.46771,\n",
       " 'global_step': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(pandas_eval_fn(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## replace input fn w/ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train-1.csv',index=False,header=False)\n",
    "df.to_csv('train-2.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.list_files('train-*.csv').flat_map(tf.data.TextLineDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1000,house,500'\n",
      "b'2000,house,1000'\n",
      "b'3000,house,3000'\n",
      "b'2000,apt,2000'\n",
      "b'1000,apt,3000'\n",
      "b'3000,apt,1000'\n",
      "b'1000,house,500'\n",
      "b'2000,house,1000'\n",
      "b'3000,house,3000'\n",
      "b'2000,apt,2000'\n",
      "b'1000,apt,3000'\n",
      "b'3000,apt,1000'\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_line(row):\n",
    "    #convert csv columns to tensors\n",
    "    cols = tf.io.decode_csv(row, record_defaults=[[0],['house'],[0]])\n",
    "    \n",
    "    features = {\n",
    "        'sq_footage':cols[0],\n",
    "        'type':cols[1]\n",
    "    }\n",
    "    labels =cols[2]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.list_files('train-*.csv').flat_map(tf.data.TextLineDataset).map(decode_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=1000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'house'>}, <tf.Tensor: shape=(), dtype=int32, numpy=500>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=2000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'house'>}, <tf.Tensor: shape=(), dtype=int32, numpy=1000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=3000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'house'>}, <tf.Tensor: shape=(), dtype=int32, numpy=3000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=2000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'apt'>}, <tf.Tensor: shape=(), dtype=int32, numpy=2000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=1000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'apt'>}, <tf.Tensor: shape=(), dtype=int32, numpy=3000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=3000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'apt'>}, <tf.Tensor: shape=(), dtype=int32, numpy=1000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=1000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'house'>}, <tf.Tensor: shape=(), dtype=int32, numpy=500>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=2000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'house'>}, <tf.Tensor: shape=(), dtype=int32, numpy=1000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=3000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'house'>}, <tf.Tensor: shape=(), dtype=int32, numpy=3000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=2000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'apt'>}, <tf.Tensor: shape=(), dtype=int32, numpy=2000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=1000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'apt'>}, <tf.Tensor: shape=(), dtype=int32, numpy=3000>)\n",
      "({'sq_footage': <tf.Tensor: shape=(), dtype=int32, numpy=3000>, 'type': <tf.Tensor: shape=(), dtype=string, numpy=b'apt'>}, <tf.Tensor: shape=(), dtype=int32, numpy=1000>)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'sq_footage': array([2000, 1000, 2000, 2000], dtype=int32),\n",
       "   'type': array([b'apt', b'apt', b'house', b'house'], dtype=object)},\n",
       "  array([2000, 3000, 1000, 1000], dtype=int32)),\n",
       " ({'sq_footage': array([3000, 1000, 3000, 3000], dtype=int32),\n",
       "   'type': array([b'house', b'house', b'apt', b'house'], dtype=object)},\n",
       "  array([3000,  500, 1000, 3000], dtype=int32)),\n",
       " ({'sq_footage': array([2000, 1000, 1000, 3000], dtype=int32),\n",
       "   'type': array([b'apt', b'apt', b'house', b'apt'], dtype=object)},\n",
       "  array([2000, 3000,  500, 1000], dtype=int32)),\n",
       " ({'sq_footage': array([3000, 1000, 2000, 2000], dtype=int32),\n",
       "   'type': array([b'house', b'apt', b'apt', b'house'], dtype=object)},\n",
       "  array([3000, 3000, 2000, 1000], dtype=int32)),\n",
       " ({'sq_footage': array([3000, 1000, 1000, 3000], dtype=int32),\n",
       "   'type': array([b'apt', b'apt', b'house', b'house'], dtype=object)},\n",
       "  array([1000, 3000,  500, 3000], dtype=int32)),\n",
       " ({'sq_footage': array([1000, 3000, 2000, 2000], dtype=int32),\n",
       "   'type': array([b'house', b'apt', b'house', b'apt'], dtype=object)},\n",
       "  array([ 500, 1000, 1000, 2000], dtype=int32))]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = dataset.shuffle(10).repeat(2).batch(4)\n",
    "list(d3.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'sq_footage': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([2000, 1000, 2000, 3000], dtype=int32)>, 'type': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'apt', b'house', b'apt', b'apt'], dtype=object)>}, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([2000,  500, 2000, 1000], dtype=int32)>)\n",
      "({'sq_footage': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1000, 3000, 2000, 1000], dtype=int32)>, 'type': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'apt', b'apt', b'house', b'apt'], dtype=object)>}, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3000, 1000, 1000, 3000], dtype=int32)>)\n",
      "({'sq_footage': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3000, 2000, 1000, 3000], dtype=int32)>, 'type': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'house', b'house', b'house', b'house'], dtype=object)>}, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3000, 1000,  500, 3000], dtype=int32)>)\n",
      "({'sq_footage': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3000, 2000, 3000, 1000], dtype=int32)>, 'type': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'house', b'house', b'apt', b'apt'], dtype=object)>}, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3000, 1000, 1000, 3000], dtype=int32)>)\n",
      "({'sq_footage': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([2000, 2000, 3000, 1000], dtype=int32)>, 'type': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'house', b'apt', b'apt', b'apt'], dtype=object)>}, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1000, 2000, 1000, 3000], dtype=int32)>)\n",
      "({'sq_footage': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1000, 1000, 2000, 3000], dtype=int32)>, 'type': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'house', b'house', b'apt', b'house'], dtype=object)>}, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 500,  500, 2000, 3000], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for item in d3:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'sq_footage': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([2000, 3000, 3000, 1000], dtype=int32)>,\n",
       "  'type': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'house', b'house', b'apt', b'apt'], dtype=object)>},\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1000, 3000, 1000, 3000], dtype=int32)>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.data.make_one_shot_iterator(d3).get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_dataset():\n",
    "    dataset=tf.data.Dataset.list_files('train-*.csv').flat_map(tf.data.TextLineDataset).map(decode_line)\n",
    "    dataset = dataset.shuffle(10).repeat(5).batch(3)\n",
    "    features, labels = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'sq_footage': <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3000, 1000, 2000], dtype=int32)>,\n",
       "  'type': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'apt', b'house', b'apt'], dtype=object)>},\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1000,  500, 2000], dtype=int32)>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'outdir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model3=tf.estimator.LinearRegressor(feat_cols,'outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2000000.0, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20...\n",
      "INFO:tensorflow:Saving checkpoints for 20 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20...\n",
      "INFO:tensorflow:Loss for final step: 2401879.2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7f2782314910>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.train(input_fn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn_dataset():\n",
    "    dataset=tf.data.Dataset.list_files('train-*.csv').flat_map(tf.data.TextLineDataset).map(decode_line)\n",
    "    dataset = dataset.batch(3)\n",
    "    features, _ = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_iter = model3.predict(predict_fn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7f2782db3250>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[746.33966, 1491.033, 2235.726, 1491.228, 746.5348, 2235.9214, 746.33966, 1491.033, 2235.726, 1491.228, 746.5348, 2235.9214]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# Read saved model and use it for prediction\n",
    "#model3=tf.estimator.LinearRegressor(feat_cols,'outdir')\n",
    "#preds_iter = model3.predict(input_fn = make_input_fn(df_valid, 1))\n",
    "print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 50))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yaay! seems to be executing eagerly again provided the ENTIRE iterator is looped over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use train_and_evaluate for managed distributed training (using AI Platform)\n",
    "\n",
    "#### - including parameter servers, exporting model to production\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('outdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:loss = 828433.2, step = 120\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 140...\n",
      "INFO:tensorflow:Saving checkpoints for 140 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 140...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-13T11:52:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-140\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Inference Time : 0.35294s\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-13-11:52:07\n",
      "INFO:tensorflow:Saving dict for global step 140: average_loss = 1288961.5, global_step = 140, label/mean = 1750.0, loss = 1288961.6, prediction/mean = 1518.2479\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 140: outdir/model.ckpt-140\n",
      "INFO:tensorflow:Loss for final step: 842396.94.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'average_loss': 1288961.5,\n",
       "  'label/mean': 1750.0,\n",
       "  'loss': 1288961.6,\n",
       "  'prediction/mean': 1518.2479,\n",
       "  'global_step': 140},\n",
       " [])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12instances *5repeat = 60instances / 3batch-size = 20 steps\n",
    "tf.estimator.train_and_evaluate(model3,tf.estimator.TrainSpec(input_fn_dataset),tf.estimator.EvalSpec(input_fn_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboard not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ./outdir\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_function():\n",
    "    json = {\n",
    "        'square_foot': tf.compat.v1.placeholder(tf.int32,[None]),#batch-size none\n",
    "        'prop_type': tf.compat.v1.placeholder(tf.string,[None])\n",
    "    }\n",
    "    \n",
    "    #tranformations on json data before submitting to features...\n",
    "    features = {\n",
    "        'sq_footage': json['square_foot'],\n",
    "        'type': json['prop_type']\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features,json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = tf.estimator.LatestExporter('pricing',serving_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                          model.ckpt-140.index\r\n",
      "graph.pbtxt                         model.ckpt-140.meta\r\n",
      "model.ckpt-100.data-00000-of-00001  model.ckpt-60.data-00000-of-00001\r\n",
      "model.ckpt-100.index                model.ckpt-60.index\r\n",
      "model.ckpt-100.meta                 model.ckpt-60.meta\r\n",
      "model.ckpt-120.data-00000-of-00001  model.ckpt-80.data-00000-of-00001\r\n",
      "model.ckpt-120.index                model.ckpt-80.index\r\n",
      "model.ckpt-120.meta                 model.ckpt-80.meta\r\n",
      "model.ckpt-140.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "%ls outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-140\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 140...\n",
      "INFO:tensorflow:Saving checkpoints for 140 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 140...\n",
      "INFO:tensorflow:loss = 1868292.4, step = 140\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 160...\n",
      "INFO:tensorflow:Saving checkpoints for 160 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 160...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-13T12:44:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-160\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Inference Time : 0.33544s\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-13-12:44:56\n",
      "INFO:tensorflow:Saving dict for global step 160: average_loss = 1288659.5, global_step = 160, label/mean = 1750.0, loss = 1288659.2, prediction/mean = 1523.9341\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 160: outdir/model.ckpt-160\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'square_foot': <tf.Tensor 'Placeholder:0' shape=(None,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(None,) dtype=string>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'square_foot': <tf.Tensor 'Placeholder:0' shape=(None,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(None,) dtype=string>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-160\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: outdir/export/pricing/temp-1594644296/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 1720867.4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'average_loss': 1288659.5,\n",
       "  'label/mean': 1750.0,\n",
       "  'loss': 1288659.2,\n",
       "  'prediction/mean': 1523.9341,\n",
       "  'global_step': 160},\n",
       " [b'outdir/export/pricing/1594644296'])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(model3,tf.estimator.TrainSpec(input_fn_dataset),\n",
    "                                tf.estimator.EvalSpec(input_fn_dataset,exporters=exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_json_local.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_json_local.txt\n",
    "{\"square_foot\":1520, \"prop_type\": \"apt\"}\n",
    "{\"square_foot\":4520, \"prop_type\": \"house\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"square_foot\":1520, \"prop_type\": \"apt\"}\r\n",
      "{\"square_foot\":4520, \"prop_type\": \"house\"}\r\n"
     ]
    }
   ],
   "source": [
    "!cat test_json_local.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1594644296\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls ./outdir/export/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb  \u001b[0m\u001b[01;34mvariables\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls ./outdir/export/pricing/1594644296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "find \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine\" -name '*.pyc' -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "non-resource variables are not supported in the long term\r\n",
      "2020-07-13 13:07:37.526526: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n",
      "2020-07-13 13:07:37.526570: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n",
      "2020-07-13 13:07:37.526613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (10937550f8c5): /proc/driver/nvidia/version does not exist\r\n",
      "2020-07-13 13:07:37.526968: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n",
      "2020-07-13 13:07:37.535482: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\r\n",
      "2020-07-13 13:07:37.535781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac64000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n",
      "2020-07-13 13:07:37.535848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:236: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:236: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\n",
      "\r\n",
      "PREDICTIONS\r\n",
      "[1159.6441650390625]\r\n",
      "[3439.43505859375]\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform local predict --model-dir ./outdir/export/pricing/1594644296 --json-instances test_json_local.txt --signature-name predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
